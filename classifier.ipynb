{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/obete/ClassifierDINOv3/blob/main/ClassifierDINOv3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oz7rYU9Jqx4P"
      },
      "source": [
        "## **DINOv3 as base with a classifier head**\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "# For ViT-Small/Base: 224x224, for ViT-Large: 384x384\n",
        "img_size = 224\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((img_size, img_size)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
        "                         std=(0.229, 0.224, 0.225))\n",
        "])\n"
      ],
      "metadata": {
        "id": "8zmHz9VzOrhE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dir = f'{DRIVE_ROOT}/train_set'\n",
        "val_dir = f'{DRIVE_ROOT}/val_set'\n",
        "\n",
        "train_dataset = ImageFolder(root=train_dir, transform=transform)\n",
        "val_dataset = ImageFolder(root=val_dir, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Class names\n",
        "print(train_dataset.classes)\n"
      ],
      "metadata": {
        "id": "VIGtKbJqOtYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Using DINOv3\n",
        "\n",
        "!pip install -U transformers"
      ],
      "metadata": {
        "collapsed": true,
        "id": "9oXLUIDJDToN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Local Inference on GPU\n",
        "Model page: https://huggingface.co/facebook/dinov3-vith16plus-pretrain-lvd1689m\n",
        "\n",
        "‚ö†Ô∏è If the generated code snippets do not work, please open an issue on either the model repo and/or on huggingface.js üôè\n",
        "\n",
        "The model you are trying to use is gated. Please make sure you have access to it by visiting the model page.To run inference, either set HF_TOKEN in your environment variables/ Secrets or run the following cell to login. ü§ó"
      ],
      "metadata": {
        "id": "0OvFae9uDl01"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "login(new_session=False)"
      ],
      "metadata": {
        "id": "jRQ8bOFXDiFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Load model directly\n",
        "from transformers import AutoImageProcessor, AutoModel\n",
        "\n",
        "processor = AutoImageProcessor.from_pretrained(\"facebook/dinov3-vith16plus-pretrain-lvd1689m\")\n",
        "backbone = AutoModel.from_pretrained(\"facebook/dinov3-vith16plus-pretrain-lvd1689m\")"
      ],
      "metadata": {
        "id": "JD9GtjqDEuyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Freeze backbone ‚Üí use DINOv3 as a fixed feature extractor.\n",
        "for param in backbone.parameters():\n",
        "    param.requires_grad = False  # freeze backbone\n"
      ],
      "metadata": {
        "id": "9vXUcVa_IU7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Custom Classification head\n",
        "import torch.nn as nn\n",
        "\n",
        "class DinoClassifier(nn.Module):\n",
        "    def __init__(self, model, num_classes):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "        self.head = nn.Linear(model.config.hidden_size, num_classes)  # simple linear head\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.model(x).last_hidden_state[:,0]  # CLS token\n",
        "        return self.head(features)\n"
      ],
      "metadata": {
        "id": "z4TZvqTPIkyd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "62b1a78a"
      },
      "source": [
        "!pip install torchmetrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model = DinoClassifier(backbone, num_classes=len(train_dataset.classes)).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "for epoch in range(5):  # Example: 5 epochs\n",
        "    model.train()\n",
        "    for imgs, labels in train_loader:\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "\n",
        "        outputs = model(imgs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n"
      ],
      "metadata": {
        "id": "1U9Lio74W_aC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchmetrics\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Define metric objects\n",
        "train_acc_metric = torchmetrics.Accuracy(task=\"multiclass\", num_classes=len(train_dataset.classes)).to(device)\n",
        "val_acc_metric   = torchmetrics.Accuracy(task=\"multiclass\", num_classes=len(train_dataset.classes)).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    # ---- Training ----\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    train_acc_metric.reset()\n",
        "    for imgs, labels in train_loader:\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "\n",
        "        outputs = model(imgs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item() * imgs.size(0)\n",
        "        train_acc_metric.update(outputs, labels)\n",
        "\n",
        "    train_loss /= len(train_dataset)\n",
        "    train_acc = train_acc_metric.compute()\n",
        "\n",
        "    # ---- Validation ----\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    val_acc_metric.reset()\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in val_loader:\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            outputs = model(imgs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            val_loss += loss.item() * imgs.size(0)\n",
        "            val_acc_metric.update(outputs, labels)\n",
        "\n",
        "    val_loss /= len(val_dataset)\n",
        "    val_acc = val_acc_metric.compute()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} \"\n",
        "          f\"| Train Loss: {train_loss:.4f}, Acc: {train_acc:.4f} \"\n",
        "          f\"| Val Loss: {val_loss:.4f}, Acc: {val_acc:.4f}\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "QuhhvOGXb5JB"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
